{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Data Analysis - Habitable Planet Hunter Dataset\n",
    "\n",
    "**Issue #57**: Identify the extent of missing data in each of the 30 approved columns.\n",
    "\n",
    "This notebook analyzes:\n",
    "- What data is missing in each column\n",
    "- How much data is missing (count and percentage)\n",
    "- Relationships between missing values across different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../datasets/full_data.csv')\n",
    "print(f\"Dataset Shape: {df.shape[0]} rows × {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 30 approved columns as per README.md\n",
    "approved_columns = [\n",
    "    # Planet Physical Properties (1-6)\n",
    "    'P_MASS', 'P_RADIUS', 'P_DENSITY', 'P_GRAVITY', 'P_ESCAPE', 'P_TYPE',\n",
    "    # Planet Orbital Parameters (7-15)\n",
    "    'P_PERIOD', 'P_SEMI_MAJOR_AXIS', 'P_ECCENTRICITY', 'P_INCLINATION', \n",
    "    'P_OMEGA', 'P_PERIASTRON', 'P_APASTRON', 'P_IMPACT_PARAMETER', 'P_HILL_SPHERE',\n",
    "    # Stellar Properties (16-26)\n",
    "    'S_MASS', 'S_RADIUS', 'S_LUMINOSITY', 'S_TEMPERATURE', 'S_AGE', \n",
    "    'S_METALLICITY', 'S_LOG_G', 'S_TYPE', 'S_MAG', 'S_DISC', 'S_MAGNETIC_FIELD',\n",
    "    # System & Meta Data (27-30)\n",
    "    'S_SNOW_LINE', 'S_TIDAL_LOCK', 'P_DETECTION', 'P_DISTANCE'\n",
    "]\n",
    "\n",
    "# Verify all columns exist in dataset\n",
    "missing_cols = [col for col in approved_columns if col not in df.columns]\n",
    "if missing_cols:\n",
    "    print(f\"Warning: Columns not found in dataset: {missing_cols}\")\n",
    "else:\n",
    "    print(f\"All {len(approved_columns)} approved columns found in dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the 30 approved columns for analysis\n",
    "df_approved = df[approved_columns].copy()\n",
    "print(f\"Analyzing {df_approved.shape[1]} columns with {df_approved.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Missing Data Summary\n",
    "\n",
    "Overview of missing values for each of the 30 approved columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate missing data statistics\n",
    "total_rows = len(df_approved)\n",
    "\n",
    "missing_stats = pd.DataFrame({\n",
    "    'Column': approved_columns,\n",
    "    'Missing Count': [df_approved[col].isna().sum() for col in approved_columns],\n",
    "    'Missing %': [round(df_approved[col].isna().sum() / total_rows * 100, 2) for col in approved_columns],\n",
    "    'Present Count': [df_approved[col].notna().sum() for col in approved_columns],\n",
    "    'Present %': [round(df_approved[col].notna().sum() / total_rows * 100, 2) for col in approved_columns],\n",
    "    'Data Type': [df_approved[col].dtype for col in approved_columns]\n",
    "})\n",
    "\n",
    "# Sort by missing percentage (descending)\n",
    "missing_stats_sorted = missing_stats.sort_values('Missing %', ascending=False).reset_index(drop=True)\n",
    "missing_stats_sorted.index = missing_stats_sorted.index + 1\n",
    "missing_stats_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Missing Data by Category\n",
    "\n",
    "Grouping the 30 columns by their category to understand patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column categories\n",
    "categories = {\n",
    "    'Planet Physical Properties': ['P_MASS', 'P_RADIUS', 'P_DENSITY', 'P_GRAVITY', 'P_ESCAPE', 'P_TYPE'],\n",
    "    'Planet Orbital Parameters': ['P_PERIOD', 'P_SEMI_MAJOR_AXIS', 'P_ECCENTRICITY', 'P_INCLINATION', \n",
    "                                   'P_OMEGA', 'P_PERIASTRON', 'P_APASTRON', 'P_IMPACT_PARAMETER', 'P_HILL_SPHERE'],\n",
    "    'Stellar Properties': ['S_MASS', 'S_RADIUS', 'S_LUMINOSITY', 'S_TEMPERATURE', 'S_AGE', \n",
    "                           'S_METALLICITY', 'S_LOG_G', 'S_TYPE', 'S_MAG', 'S_DISC', 'S_MAGNETIC_FIELD'],\n",
    "    'System & Meta Data': ['S_SNOW_LINE', 'S_TIDAL_LOCK', 'P_DETECTION', 'P_DISTANCE']\n",
    "}\n",
    "\n",
    "# Calculate category-level statistics\n",
    "category_stats = []\n",
    "for category, cols in categories.items():\n",
    "    total_cells = len(cols) * total_rows\n",
    "    missing_cells = df_approved[cols].isna().sum().sum()\n",
    "    avg_missing = round(missing_cells / total_cells * 100, 2)\n",
    "    category_stats.append({\n",
    "        'Category': category,\n",
    "        'Columns': len(cols),\n",
    "        'Total Cells': total_cells,\n",
    "        'Missing Cells': missing_cells,\n",
    "        'Avg Missing %': avg_missing\n",
    "    })\n",
    "\n",
    "category_df = pd.DataFrame(category_stats)\n",
    "category_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Visualization: Missing Data Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create missing data visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart of missing percentages\n",
    "colors = ['#e74c3c' if x > 50 else '#f39c12' if x > 20 else '#27ae60' for x in missing_stats_sorted['Missing %']]\n",
    "axes[0].barh(missing_stats_sorted['Column'], missing_stats_sorted['Missing %'], color=colors)\n",
    "axes[0].set_xlabel('Missing Percentage (%)')\n",
    "axes[0].set_ylabel('Column')\n",
    "axes[0].set_title('Missing Data Percentage by Column')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].axvline(x=50, color='red', linestyle='--', alpha=0.5, label='50% threshold')\n",
    "axes[0].axvline(x=20, color='orange', linestyle='--', alpha=0.5, label='20% threshold')\n",
    "axes[0].legend()\n",
    "\n",
    "# Category-level pie chart\n",
    "axes[1].pie(category_df['Missing Cells'], labels=category_df['Category'], autopct='%1.1f%%', \n",
    "            colors=['#3498db', '#9b59b6', '#e67e22', '#1abc9c'])\n",
    "axes[1].set_title('Distribution of Missing Values by Category')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Missing Data Correlation Analysis\n",
    "\n",
    "Analyzing relationships between missing values across columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a binary matrix: 1 = missing, 0 = present\n",
    "missing_matrix = df_approved.isna().astype(int)\n",
    "\n",
    "# Calculate correlation between missing patterns\n",
    "missing_corr = missing_matrix.corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "mask = np.triu(np.ones_like(missing_corr, dtype=bool))\n",
    "sns.heatmap(missing_corr, mask=mask, annot=False, cmap='RdYlBu_r', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={'shrink': 0.8})\n",
    "plt.title('Correlation Between Missing Values Across Columns\\n(Higher values = columns tend to be missing together)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find highly correlated missing patterns (correlation > 0.5)\n",
    "high_corr_pairs = []\n",
    "for i in range(len(approved_columns)):\n",
    "    for j in range(i+1, len(approved_columns)):\n",
    "        corr_val = missing_corr.iloc[i, j]\n",
    "        if abs(corr_val) > 0.5:\n",
    "            high_corr_pairs.append({\n",
    "                'Column 1': approved_columns[i],\n",
    "                'Column 2': approved_columns[j],\n",
    "                'Correlation': round(corr_val, 3)\n",
    "            })\n",
    "\n",
    "if high_corr_pairs:\n",
    "    corr_df = pd.DataFrame(high_corr_pairs).sort_values('Correlation', ascending=False)\n",
    "    print(\"Highly Correlated Missing Patterns (|correlation| > 0.5):\")\n",
    "    display(corr_df)\n",
    "else:\n",
    "    print(\"No highly correlated missing patterns found (threshold: 0.5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Missing Data Patterns Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze rows with most missing values\n",
    "missing_per_row = df_approved.isna().sum(axis=1)\n",
    "\n",
    "print(\"Missing Values Distribution Across Rows:\")\n",
    "print(f\"  - Rows with 0 missing values: {(missing_per_row == 0).sum()}\")\n",
    "print(f\"  - Rows with 1-5 missing values: {((missing_per_row >= 1) & (missing_per_row <= 5)).sum()}\")\n",
    "print(f\"  - Rows with 6-10 missing values: {((missing_per_row >= 6) & (missing_per_row <= 10)).sum()}\")\n",
    "print(f\"  - Rows with 11-15 missing values: {((missing_per_row >= 11) & (missing_per_row <= 15)).sum()}\")\n",
    "print(f\"  - Rows with 16-20 missing values: {((missing_per_row >= 16) & (missing_per_row <= 20)).sum()}\")\n",
    "print(f\"  - Rows with >20 missing values: {(missing_per_row > 20).sum()}\")\n",
    "print(f\"\\n  - Average missing values per row: {round(missing_per_row.mean(), 2)}\")\n",
    "print(f\"  - Max missing values in a row: {missing_per_row.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of missing values per row\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(missing_per_row, bins=range(0, 32), edgecolor='black', alpha=0.7, color='#3498db')\n",
    "plt.xlabel('Number of Missing Values')\n",
    "plt.ylabel('Number of Rows')\n",
    "plt.title('Distribution of Missing Values Per Row (30 Approved Columns)')\n",
    "plt.axvline(x=missing_per_row.mean(), color='red', linestyle='--', label=f'Mean: {missing_per_row.mean():.1f}')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Detection Method Impact on Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze missing data by detection method\n",
    "if 'P_DETECTION' in df_approved.columns:\n",
    "    detection_missing = df_approved.groupby('P_DETECTION').apply(\n",
    "        lambda x: x.isna().sum().sum() / (len(x) * len(approved_columns)) * 100\n",
    "    ).round(2)\n",
    "    \n",
    "    detection_counts = df_approved['P_DETECTION'].value_counts()\n",
    "    \n",
    "    detection_analysis = pd.DataFrame({\n",
    "        'Detection Method': detection_missing.index,\n",
    "        'Planet Count': [detection_counts.get(m, 0) for m in detection_missing.index],\n",
    "        'Avg Missing %': detection_missing.values\n",
    "    }).sort_values('Planet Count', ascending=False)\n",
    "    \n",
    "    print(\"Missing Data by Detection Method:\")\n",
    "    display(detection_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "total_cells = df_approved.shape[0] * df_approved.shape[1]\n",
    "total_missing = df_approved.isna().sum().sum()\n",
    "total_present = total_cells - total_missing\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MISSING DATA ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDataset Overview:\")\n",
    "print(f\"  - Total Rows: {df_approved.shape[0]:,}\")\n",
    "print(f\"  - Columns Analyzed: {df_approved.shape[1]}\")\n",
    "print(f\"  - Total Data Points: {total_cells:,}\")\n",
    "\n",
    "print(f\"\\nMissing Data Overview:\")\n",
    "print(f\"  - Total Missing Values: {total_missing:,}\")\n",
    "print(f\"  - Total Present Values: {total_present:,}\")\n",
    "print(f\"  - Overall Missing Rate: {round(total_missing/total_cells*100, 2)}%\")\n",
    "\n",
    "print(f\"\\nColumn-Level Statistics:\")\n",
    "print(f\"  - Columns with 0% missing: {(missing_stats['Missing %'] == 0).sum()}\")\n",
    "print(f\"  - Columns with <10% missing: {(missing_stats['Missing %'] < 10).sum()}\")\n",
    "print(f\"  - Columns with 10-50% missing: {((missing_stats['Missing %'] >= 10) & (missing_stats['Missing %'] < 50)).sum()}\")\n",
    "print(f\"  - Columns with ≥50% missing: {(missing_stats['Missing %'] >= 50).sum()}\")\n",
    "\n",
    "print(f\"\\nMost Complete Columns (Top 5):\")\n",
    "for idx, row in missing_stats.nsmallest(5, 'Missing %').iterrows():\n",
    "    print(f\"  - {row['Column']}: {row['Missing %']}% missing\")\n",
    "\n",
    "print(f\"\\nMost Incomplete Columns (Top 5):\")\n",
    "for idx, row in missing_stats.nlargest(5, 'Missing %').iterrows():\n",
    "    print(f\"  - {row['Column']}: {row['Missing %']}% missing\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Detailed Column Analysis Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive table with all details\n",
    "detailed_analysis = missing_stats.copy()\n",
    "\n",
    "# Add category information\n",
    "def get_category(col):\n",
    "    for cat, cols in categories.items():\n",
    "        if col in cols:\n",
    "            return cat\n",
    "    return 'Unknown'\n",
    "\n",
    "detailed_analysis['Category'] = detailed_analysis['Column'].apply(get_category)\n",
    "\n",
    "# Reorder columns\n",
    "detailed_analysis = detailed_analysis[['Column', 'Category', 'Data Type', 'Present Count', 'Present %', 'Missing Count', 'Missing %']]\n",
    "\n",
    "# Style the dataframe\n",
    "def highlight_missing(val):\n",
    "    if isinstance(val, (int, float)):\n",
    "        if val >= 50:\n",
    "            return 'background-color: #ffcccc'\n",
    "        elif val >= 20:\n",
    "            return 'background-color: #fff3cd'\n",
    "    return ''\n",
    "\n",
    "styled_df = detailed_analysis.style.applymap(highlight_missing, subset=['Missing %'])\n",
    "styled_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
