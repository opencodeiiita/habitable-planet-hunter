{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13716c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268e1de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ece2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Config\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ce5173",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "MODEL_DIR = \"./Models\"\n",
    "MODEL_PATH = os.path.join(MODEL_DIR, \"habitable_planet_model_irs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd837af",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "def ensure_dir(path: str):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a1f492",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "def load_dataset(file_path: str) -> pd.DataFrame:\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Dataset file not found: {file_path}\")\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Dataset loaded | Shape: {df.shape}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eec6186",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "def select_features_and_target(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    allowed_features = [\n",
    "        'P_MASS', 'P_RADIUS', 'P_DENSITY', 'P_GRAVITY', 'P_ESCAPE', 'P_TYPE',\n",
    "        'P_PERIOD', 'P_SEMI_MAJOR_AXIS', 'P_ECCENTRICITY', 'P_INCLINATION',\n",
    "        'P_OMEGA', 'P_PERIASTRON', 'P_APASTRON', 'P_IMPACT_PARAMETER', 'P_HILL_SPHERE',\n",
    "        'S_MASS', 'S_RADIUS', 'S_LUMINOSITY', 'S_TEMPERATURE', 'S_AGE',\n",
    "        'S_METALLICITY', 'S_LOG_G', 'S_TYPE', 'S_MAG', 'S_DISC', 'S_MAGNETIC_FIELD',\n",
    "        'S_SNOW_LINE', 'S_TIDAL_LOCK', 'P_DETECTION', 'P_DISTANCE'\n",
    "    ]\n",
    "\n",
    "    target_column = 'P_HABITABLE'\n",
    "\n",
    "    df = df[allowed_features + [target_column]].copy()\n",
    "    df['Target'] = df[target_column].astype(str).str.lower().map({'yes': 1, 'no': 0})\n",
    "    df.drop(columns=[target_column], inplace=True)\n",
    "\n",
    "    print(\"Target Distribution:\\n\", df['Target'].value_counts(normalize=True))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a752ab2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "class LabelEncoderWrapper:\n",
    "    \"\"\"Sklearn-compatible wrapper for LabelEncoder\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.encoders = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = pd.DataFrame(X)\n",
    "        for col in X.columns:\n",
    "            le = LabelEncoder()\n",
    "            le.fit(X[col].astype(str))\n",
    "            self.encoders[col] = le\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        for col, le in self.encoders.items():\n",
    "            X[col] = le.transform(X[col].astype(str))\n",
    "        return X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d511cff1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def build_preprocessor(X: pd.DataFrame) -> ColumnTransformer:\n",
    "\n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "    numerical_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "    num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    cat_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', LabelEncoderWrapper())\n",
    "    ])\n",
    "\n",
    "    return ColumnTransformer([\n",
    "        ('num', num_pipeline, numerical_cols),\n",
    "        ('cat', cat_pipeline, categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d9c58b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Model Training\n",
    "def train_model(X_train, y_train, preprocessor) -> Pipeline:\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        random_state=RANDOM_SEED,\n",
    "        n_jobs=-1,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', rf)\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'classifier__n_estimators': [200, 300, 400],\n",
    "        'classifier__max_depth': [None, 10, 20],\n",
    "        'classifier__min_samples_split': [2, 5],\n",
    "        'classifier__min_samples_leaf': [1, 2]\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=20,\n",
    "        scoring='roc_auc',\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_SEED\n",
    "    )\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best Parameters:\", search.best_params_)\n",
    "    return search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92e66ec",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def evaluate_model(model: Pipeline, X_test, y_test):\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, preds) * 100:.2f}%\")\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_test, probs):.4f}\\n\")\n",
    "\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, preds))\n",
    "\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    plot_confusion_matrix(cm)\n",
    "    plot_roc_curve(y_test, probs)\n",
    "    plot_precision_recall(y_test, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2af4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "def plot_confusion_matrix(cm):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43436df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_true, probs):\n",
    "    fpr, tpr, _ = roc_curve(y_true, probs)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot(fpr, tpr, linewidth=2)\n",
    "    plt.plot([0, 1], [0, 1], '--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93637a01",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_precision_recall(y_true, probs):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, probs)\n",
    "    ap = average_precision_score(y_true, probs)\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot(recall, precision, linewidth=2)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve (AP={ap:.3f})')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ff57c8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Model Saving\n",
    "def save_model(model: Pipeline):\n",
    "    ensure_dir(MODEL_DIR)\n",
    "    with open(MODEL_PATH, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"Model saved at: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311ff4a8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Main Pipeline\n",
    "def main():\n",
    "\n",
    "    dataset_path = \"../data/full_data.csv\"\n",
    "\n",
    "    df = load_dataset(dataset_path)\n",
    "    df = select_features_and_target(df)\n",
    "\n",
    "    X = df.drop(columns=['Target'])\n",
    "    y = df['Target']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y\n",
    "    )\n",
    "\n",
    "    preprocessor = build_preprocessor(X)\n",
    "\n",
    "    model = train_model(X_train, y_train, preprocessor)\n",
    "\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "\n",
    "    save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3423cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
